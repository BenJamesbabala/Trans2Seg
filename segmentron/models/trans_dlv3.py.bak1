import torch
import torch.nn as nn
import torch.nn.functional as F

from .segbase import SegBaseModel
from .model_zoo import MODEL_REGISTRY
from ..modules import _ConvBNReLU, SeparableConv2d, _ASPP, _FCNHead
from ..config import cfg
from ..modules import VisionTransformer
from IPython import embed


__all__ = ['DeepLabV3Plus']


@MODEL_REGISTRY.register(name='TransDLV3')
class TransDLV3(SegBaseModel):

    def __init__(self):
        super(TransDLV3, self).__init__()
        if self.backbone.startswith('mobilenet'):
            c1_channels = 24
            c4_channels = 320
        else:
            c1_channels = 256
            c4_channels = 2048

        vit_params = cfg.MODEL.TRANS_DLV3
        self.head = _Head(self.nclass, vit_params, c1_channels=c1_channels, c4_channels=c4_channels)
        if self.aux:
            self.auxlayer = _FCNHead(728, self.nclass)
        self.__setattr__('decoder', ['head', 'auxlayer'] if self.aux else ['head'])


    def forward(self, x):
        size = x.size()[2:]
        c1, c2, c3, c4 = self.encoder(x) # resnet50 backbone

        outputs = list()
        x = self.head(c4, c1)
        x = F.interpolate(x, size, mode='bilinear', align_corners=True)

        outputs.append(x)
        if self.aux:
            auxout = self.auxlayer(c3)
            auxout = F.interpolate(auxout, size, mode='bilinear', align_corners=True)
            outputs.append(auxout)
        return tuple(outputs)


class Transformer(nn.Module):
    def __init__(self, vit_params, c4_channels=2048, use_decoder=False):
        super().__init__()
        last_channels = vit_params['embed_dim']
        self.vit = VisionTransformer(input_dim=c4_channels,
                                     embed_dim=last_channels,
                                     depth=vit_params['depth'],
                                     num_heads=vit_params['num_heads'],
                                     mlp_ratio=vit_params['mlp_ratio'])

        self.use_decoder = use_decoder

    def forward(self, x):
        n, _, h, w = x.shape
        x = self.vit.hybrid_embed(x)
        cls_token, x = self.vit.forward_encoder(x)
        if self.use_decoder:
            attns_list = self.vit.forward_decoder(x)

        attns_list = [attn.reshape(n, -1, h, w) for attn in attns_list]

        x = x.reshape(n, h, w, -1).permute(0, 3, 1, 2)
        return x, attns_list


class _Head(nn.Module):
    def __init__(self, nclass, vit_params, c1_channels=256, c4_channels=2048, norm_layer=nn.BatchNorm2d):
        super(_Head, self).__init__()

        last_channels = vit_params['embed_dim']
        # decoder
        self.use_decoder = True

        self.trans = Transformer(vit_params, c4_channels=c4_channels, use_decoder=self.use_decoder)

        self.c1_block = _ConvBNReLU(c1_channels, 48, 1, norm_layer=norm_layer)
        last_channels += 48

        self.fuse_head = nn.Sequential(
            SeparableConv2d(last_channels, 256, 3, norm_layer=norm_layer, relu_first=False),
            SeparableConv2d(256, 256, 3, norm_layer=norm_layer, relu_first=False))

        self.pred_head = nn.Conv2d(256, nclass, 1)

        ##########
        self.conv1 = _ConvBNReLU(c1_channels, nclass, 1, norm_layer=norm_layer)
        self.conv2 = nn.Sequential(
            SeparableConv2d(nclass, nclass, 3, norm_layer=norm_layer, relu_first=False),
            SeparableConv2d(nclass, nclass, 3, norm_layer=norm_layer, relu_first=False))
        self.conv3 = nn.Conv2d(nclass, nclass, 1)

    def forward(self, x, c1):

        # transformer
        feat_enc, attns_list = self.trans(x)
        x = feat_enc
        attn_map = attns_list[-1]

        # 随便写一个head
        size = c1.size()[2:]
        attn_map = F.interpolate(attn_map, size, mode='bilinear', align_corners=True)
        c1 = self.conv1(c1)
        attn_map = attn_map + c1
        attn_map = self.conv2(attn_map)
        result = self.conv3(attn_map)
        # embed()

        # reduce dim of C1
        # size = c1.size()[2:]
        # x = F.interpolate(x, size, mode='bilinear', align_corners=True)
        # c1 = self.c1_block(c1)

        # fuse C1 and C4
        # x = self.fuse_head(torch.cat([x, c1], dim=1))
        #
        # # final prediction head
        # result = self.pred_head(x)
        return result

        return self.block(x)


